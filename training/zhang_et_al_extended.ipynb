{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d1c4d4f-ec98-4cae-809a-c46e268379fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils import z_normalize_column, synchronize_trials, remove_artifacts_from_column, bandpass, segment_column, decompose_segment, extract_features, train\n",
    "from plots import plot_preprocessing, plot_sample_durations, plot_eeg_gradcpt_time_diff\n",
    "\n",
    "subject_id = 1\n",
    "\n",
    "eeg_data_1 = pd.read_csv(f'data/subject{subject_id}/muselsl-session1-1.csv')\n",
    "gradcpt_data_1 = pd.read_csv(f'data/subject{subject_id}/gradcpt-session1-1.csv')\n",
    "eeg_data_2 = pd.read_csv(f'data/subject{subject_id}/muselsl-session1-2.csv')\n",
    "gradcpt_data_2 = pd.read_csv(f'data/subject{subject_id}/gradcpt-session1-2.csv')\n",
    "eeg_data_3 = pd.read_csv(f'data/subject{subject_id}/muselsl-session1-3.csv')\n",
    "gradcpt_data_3 = pd.read_csv(f'data/subject{subject_id}/gradcpt-session1-3.csv')\n",
    "\n",
    "# Channels\n",
    "channels = ['AF7', 'AF8', 'TP9', 'TP10'] \n",
    "\n",
    "# Add a column to indicate the trial number\n",
    "eeg_data_1['trial'] = 1\n",
    "gradcpt_data_1['trial'] = 1\n",
    "eeg_data_2['trial'] = 2\n",
    "gradcpt_data_2['trial'] = 2\n",
    "eeg_data_3['trial'] = 3\n",
    "gradcpt_data_3['trial'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71aad2a8-1972-4125-a34e-b3a1ce29f775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradcpt data had to be truncated\n"
     ]
    }
   ],
   "source": [
    "# Sync trial start and end times\n",
    "\n",
    "eeg_data_1, gradcpt_data_1 = synchronize_trials(eeg_data_1, gradcpt_data_1)\n",
    "eeg_data_2, gradcpt_data_2 = synchronize_trials(eeg_data_2, gradcpt_data_2)\n",
    "eeg_data_3, gradcpt_data_3 = synchronize_trials(eeg_data_3, gradcpt_data_3)\n",
    "\n",
    "# Concatenate the trials\n",
    "eeg_data = pd.concat([\n",
    "    eeg_data_1, \n",
    "    eeg_data_2, \n",
    "    eeg_data_3\n",
    "], ignore_index=True)\n",
    "gradcpt_data = pd.concat([\n",
    "    gradcpt_data_1, \n",
    "    gradcpt_data_2, \n",
    "    gradcpt_data_3\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752ce2f5-3a22-41ce-9756-5f35b0b2038c",
   "metadata": {},
   "source": [
    "### z-normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3e505a0-5eef-44a7-a233-5716757efd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in channels:\n",
    "    eeg_data[f'{channel}_normal'] = z_normalize_column(eeg_data[channel])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03103643-592b-4d44-b190-d1e08abaf981",
   "metadata": {},
   "source": [
    "### Artificat removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "890460ca-2e22-4265-a95d-1cbd8b53d812",
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in channels:\n",
    "    eeg_data[f'{channel}_artif_removed'] = remove_artifacts_from_column(eeg_data[f'{channel}_normal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b290cbc-9727-4770-a42c-50882d358cca",
   "metadata": {},
   "source": [
    "### Bandpass filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0563b34f-49c1-43af-96ba-f8ef874456ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in channels:\n",
    "    eeg_data[f'{channel}_bandpassed'] = bandpass(eeg_data[f'{channel}_artif_removed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026ea83d-98dd-4030-b490-491d458045ab",
   "metadata": {},
   "source": [
    "### Separate trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2822adf8-13ca-470e-bad9-86b655cd2409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate preprocessed data back into individual trials\n",
    "eeg_data_t1 = eeg_data[eeg_data['trial'] == 1].drop(columns=['trial'])\n",
    "gradcpt_data_t1 = gradcpt_data[gradcpt_data['trial'] == 1].drop(columns=['trial'])\n",
    "\n",
    "eeg_data_t2 = eeg_data[eeg_data['trial'] == 2].drop(columns=['trial']).reset_index(drop=True)\n",
    "gradcpt_data_t2 = gradcpt_data[gradcpt_data['trial'] == 2].drop(columns=['trial']).reset_index(drop=True)\n",
    "\n",
    "eeg_data_t3 = eeg_data[eeg_data['trial'] == 3].drop(columns=['trial']).reset_index(drop=True)\n",
    "gradcpt_data_t3 = gradcpt_data[gradcpt_data['trial'] == 3].drop(columns=['trial']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97700e0b-77a6-4e09-971f-d3237bc8da2f",
   "metadata": {},
   "source": [
    "### Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7af8470a-8c21-4e14-82a2-8215a476aa36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 Done\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty DataFrames for each trial\n",
    "features_t1 = pd.DataFrame()\n",
    "features_t2 = pd.DataFrame()\n",
    "features_t3 = pd.DataFrame()\n",
    "\n",
    "for trial in [1, 2, 3]:\n",
    "    # Select the current trial data\n",
    "    if trial == 1:\n",
    "        cur_eeg_df = eeg_data_t1\n",
    "        cur_gcpt_df = gradcpt_data_t1\n",
    "    elif trial == 2:\n",
    "        cur_eeg_df = eeg_data_t2\n",
    "        cur_gcpt_df = gradcpt_data_t2\n",
    "    else:\n",
    "        cur_eeg_df = eeg_data_t3\n",
    "        cur_gcpt_df = gradcpt_data_t3\n",
    "    \n",
    "    # Process each channel\n",
    "    for i, channel in enumerate(channels):\n",
    "        # Segment the current EEG data\n",
    "        segments = segment_column(cur_eeg_df[f'{channel}_bandpassed'], cur_gcpt_df)\n",
    "        # Decompose each segment\n",
    "        segment_bands = [decompose_segment(segment) for segment in segments]\n",
    "        # Extract features from the decomposed segments\n",
    "        features = extract_features(channel, segment_bands, True)\n",
    "        \n",
    "        # Append the features to the respective DataFrame\n",
    "        if trial == 1:\n",
    "            features_t1 = pd.concat([features_t1, features], axis=1)\n",
    "        elif trial == 2:\n",
    "            features_t2 = pd.concat([features_t2, features], axis=1)\n",
    "        else:\n",
    "            features_t3 = pd.concat([features_t3, features], axis=1)\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        print(f'{(trial-1)*len(channels)+i+1}/{3*len(channels)} Done')\n",
    "\n",
    "features_t1['in_the_zone'] = gradcpt_data_t1['in_the_zone']\n",
    "features_t2['in_the_zone'] = gradcpt_data_t2['in_the_zone']\n",
    "features_t3['in_the_zone'] = gradcpt_data_t3['in_the_zone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "666cb26b-df01-4521-8df4-df855aadfff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features_df = pd.concat([features_t1, features_t2, features_t3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf775b00-cb01-4dd3-a0d8-c6064032ef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features_df.shape\n",
    "n_feats = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09f55eb3-458f-4f73-a263-30d838a635a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "af7_df = combined_features_df.iloc[:, list(range(0, 600)) + [-1]].copy()\n",
    "af8_df = combined_features_df.iloc[:, list(range(n_feats, n_feats*2)) + [-1]].copy()\n",
    "tp9_df = combined_features_df.iloc[:, list(range(n_feats*2, n_feats*3)) + [-1]].copy()\n",
    "tp10_df = combined_features_df.iloc[:, list(range(n_feats*3, n_feats*4)) + [-1]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cad6d06-b266-462b-b6d0-5d916eee5074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0/25 in progress\n",
      "2.0/25 in progress\n",
      "3.0/25 in progress\n",
      "4.0/25 in progress\n",
      "5.0/25 in progress\n",
      "6.0/25 in progress\n",
      "7.0/25 in progress\n",
      "8.0/25 in progress\n",
      "9.0/25 in progress\n",
      "10.0/25 in progress\n",
      "11.0/25 in progress\n",
      "12.0/25 in progress\n",
      "13.0/25 in progress\n",
      "14.0/25 in progress\n",
      "15.0/25 in progress\n",
      "16.0/25 in progress\n",
      "17.0/25 in progress\n",
      "18.0/25 in progress\n",
      "19.0/25 in progress\n",
      "20.0/25 in progress\n",
      "21.0/25 in progress\n",
      "22.0/25 in progress\n",
      "23.0/25 in progress\n",
      "24.0/25 in progress\n",
      "25.0/25 in progress\n"
     ]
    }
   ],
   "source": [
    "features_range = list(range(10, 260, 10))\n",
    "channels = ['AF7', 'AF8', 'TP9', 'TP10', 'Combined']\n",
    "metrics = ['train_acc', 'test_acc', 'f1_score']\n",
    "\n",
    "data = []\n",
    "\n",
    "subject_data = {\n",
    "    subject_id: {'AF7': af7_df, 'AF8': af8_df, 'TP9': tp9_df, 'TP10': tp10_df, 'Combined': combined_features_df},\n",
    "}\n",
    "\n",
    "for subject, datasets in subject_data.items():\n",
    "    for feats in features_range:\n",
    "        print(f'{feats/10}/25 in progress')\n",
    "        for channel, df in datasets.items():\n",
    "            metrics_result = train(runs=2, num_features=feats, df=df)\n",
    "            for metric in metrics:\n",
    "                data.append({\n",
    "                    'Subject': subject,\n",
    "                    'Channel': channel,\n",
    "                    'Num_Features': feats,\n",
    "                    'Metric': metric,\n",
    "                    'Value': metrics_result.get(metric)\n",
    "                })\n",
    "\n",
    "results_df = pd.DataFrame(data)\n",
    "\n",
    "results_df.to_csv(f'subject_{subject_id}_extended_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab97eb52-bd86-4cff-9804-6d64f0c472fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
